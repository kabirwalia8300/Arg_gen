{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "huggingfaceTutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPFVHOyj+n40XfWV+yWEYpw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kabirwalia8300/Arg_gen/blob/master/huggingfaceTutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgrGZNzX4sO9",
        "colab_type": "text"
      },
      "source": [
        "## Fine Tuning Transformer XL using Arguana Corpus for Argument Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW7IzY8w72By",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d83dc560-87ff-4f2c-9b09-2a9150a710cd"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZAATKCOh-2b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9bd8af5a-097f-4c84-b8bc-92b587e73846"
      },
      "source": [
        "# !git clone https://github.com/huggingface/transformers.git\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive\tsample_data  test.csv  train.csv  transformers\tval.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch9olUGyiwU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install ./transformers/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnB4_nii3iAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import os, sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Torchtext\n",
        "from torchtext.data import Field, BucketIterator, TabularDataset\n",
        "\n",
        "#Huggingface\n",
        "from transformers import TransfoXLConfig, TransfoXLModel, TransfoXLTokenizer, TransfoXLLMHeadModel\n",
        "from transformers.tokenization_transfo_xl import LMOrderedIterator\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoAQhEDB3l8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/kabirwalia8300/Arg_gen/master/Seq2Seq/args2.csv'\n",
        "df = pd.read_csv(url, error_bad_lines=False).iloc[:, 1:]\n",
        "# removing duplicates\n",
        "df = df.drop_duplicates(subset='Arguments', keep=\"first\")\n",
        "df['Arguments'] = [x.split('\\n\\n', 1)[1] for x in df['Arguments']]\n",
        "df_train, test = train_test_split(df, test_size=0.02)\n",
        "train, val = train_test_split(df_train, test_size = 0.05)\n",
        "train = train[['Arguments', 'Counters']]\n",
        "val = val[['Arguments', 'Counters']]\n",
        "test = test[['Arguments', 'Counters']]\n",
        "train.to_csv('./train.csv', header=False, index=False)\n",
        "val.to_csv('./val.csv', header=False, index=False)\n",
        "test.to_csv('./test.csv', header=False, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5XVXorBzEkA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "98604cfe-ead0-417c-beed-aaaad29eff1e"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EfktVIdeHgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transformer XL Tokenizer\n",
        "tok = TransfoXLTokenizer.from_pretrained(\"transfo-xl-wt103\", do_lower_case=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCJZhsffdLxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ARGUMENT = Field(tokenize=tok.encode,\n",
        "#                 use_vocab=False,\n",
        "#                 init_token=tok.cls_token_id,\n",
        "#                 eos_token=tok.sep_token_id,\n",
        "#                 include_lengths=True,\n",
        "#                 pad_token=tok.pad_token_id,\n",
        "#                 unk_token=tok.unk_token_id,\n",
        "#                 batch_first=True,\n",
        "#                 )\n",
        "# COUNTER = Field(tokenize=tok.encode,\n",
        "#                 use_vocab=False,\n",
        "#                 init_token=tok.cls_token_id,\n",
        "#                 eos_token=tok.sep_token_id,\n",
        "#                 pad_token=tok.pad_token_id,\n",
        "#                 unk_token=tok.unk_token_id,\n",
        "#                 batch_first=True,\n",
        "#                 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bhl9hTTpdLG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #set up vocab for article and summary from train data.\n",
        "# ARGUMENT.build_vocab(train_data, min_freq=2)\n",
        "# COUNTER.build_vocab(train_data, min_freq=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW450-hudLEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "  'Characterizes a dataset for PyTorch'\n",
        "  def __init__(self, list_IDs, labels):\n",
        "        'Initialization'\n",
        "        self.labels = labels\n",
        "        self.list_IDs = list_IDs\n",
        "\n",
        "  def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.list_IDs)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        # Select sample\n",
        "        ID = self.list_IDs[index]\n",
        "\n",
        "        # Load data and get label\n",
        "        X = torch.load('data/' + ID + '.pt')\n",
        "        y = self.labels[ID]\n",
        "\n",
        "        return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flbM_R8tZpS4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ-7DE8i-032",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxQQ1nL7QA0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=3,\n",
        "    per_gpu_train_batch_size=64,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset,\n",
        "    prediction_loss_only=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}